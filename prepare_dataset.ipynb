{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "## BASH script for checking the files \n",
    "\n",
    "# List of all the files: \n",
    "find . -name *CO4* -maxdepth 3 -mindepth 3 > /nfs/research/birney/users/fanny/medaka/ziram_analysis/list_files_01062023.txt\n",
    "\n",
    "# Count number of files per plate / per line (can help to see which are missing):\n",
    "find . -name *CO4* -maxdepth 3 -mindepth 3 |cut -d/ -f2 | sort  | uniq -c | tee /nfs/research/birney/users/fanny/medaka/Ziram_analysis/number_files_per_plates_01062023.txt\n",
    "find . -name *CO4* -maxdepth 3 -mindepth 3 |cut -d/ -f3 | cut -d ' ' -f1 | sort  | uniq -c | tee /nfs/research/birney/users/fanny/medaka/Ziram_analysis/number_files_per_line_01062023.txt\n",
    "\n",
    "# Modification of files encoding (not workinng on the cluster because miss library)\n",
    "find . -name *.tif -exec ./ffmpeg -i {} -pix_fmt rgb8 -y {}.png \\;\n",
    "for i in test_set/*.tif; do ./ffmpeg -i \"$i\" -pix_fmt pal8 -y \"${i%.*}.png\"; done\n",
    "\n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = pd.read_table(file, header=None)\n",
    "files[['plate', 'well']] = files[0].str.split('/', expand=True)[[0, 2]]\n",
    "files['well'] = files['well'].str.split('---', n=1, expand=True)[0].str.replace('WE00', '').astype(int).astype(str)\n",
    "files['plate'] = files['plate'].str.split('_', n=1, expand=True)[0].astype(str)\n",
    "files['plate_well'] = files['plate'] + '_' + files['well'].astype(int).astype(str)\n",
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1726, 12)\n",
      "(932, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_exposure</th>\n",
       "      <th>line</th>\n",
       "      <th>exposure_type</th>\n",
       "      <th>stop_exposure</th>\n",
       "      <th>fixed</th>\n",
       "      <th>imaged</th>\n",
       "      <th>plate_#</th>\n",
       "      <th>well_#</th>\n",
       "      <th>kinked</th>\n",
       "      <th>#_kinks</th>\n",
       "      <th>severity_score</th>\n",
       "      <th>plate_well</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>117-1</td>\n",
       "      <td>Ziram</td>\n",
       "      <td>2022-07-30</td>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>2022-08-18 00:00:00</td>\n",
       "      <td>Plate 8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Plate 8_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>117-1</td>\n",
       "      <td>Ziram</td>\n",
       "      <td>2022-07-30</td>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>2022-08-18 00:00:00</td>\n",
       "      <td>Plate 8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Plate 8_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>117-1</td>\n",
       "      <td>Ziram</td>\n",
       "      <td>2022-07-30</td>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>2022-08-18 00:00:00</td>\n",
       "      <td>Plate 8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Plate 8_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>117-1</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>2022-07-30</td>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>2022-08-22 00:00:00</td>\n",
       "      <td>Plate 10</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Plate 10_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>117-1</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>2022-07-30</td>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>2022-08-22 00:00:00</td>\n",
       "      <td>Plate 10</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Plate 10_49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_exposure   line exposure_type stop_exposure      fixed  \\\n",
       "0     2022-07-20  117-1         Ziram    2022-07-30 2022-08-04   \n",
       "1     2022-07-20  117-1         Ziram    2022-07-30 2022-08-04   \n",
       "2     2022-07-20  117-1         Ziram    2022-07-30 2022-08-04   \n",
       "5     2022-07-20  117-1          DMSO    2022-07-30 2022-08-04   \n",
       "6     2022-07-20  117-1          DMSO    2022-07-30 2022-08-04   \n",
       "\n",
       "                imaged   plate_#  well_# kinked #_kinks  severity_score  \\\n",
       "0  2022-08-18 00:00:00   Plate 8    13.0      1     10+             4.0   \n",
       "1  2022-08-18 00:00:00   Plate 8    14.0      1     10+             4.0   \n",
       "2  2022-08-18 00:00:00   Plate 8    15.0      1     10+             4.0   \n",
       "5  2022-08-22 00:00:00  Plate 10    37.0      0       0             0.0   \n",
       "6  2022-08-22 00:00:00  Plate 10    49.0      0       0             0.0   \n",
       "\n",
       "    plate_well  \n",
       "0   Plate 8_13  \n",
       "1   Plate 8_14  \n",
       "2   Plate 8_15  \n",
       "5  Plate 10_37  \n",
       "6  Plate 10_49  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_excel('Germany Data Organized.xlsx', engine='openpyxl')\n",
    "print(metadata.shape)\n",
    "metadata.dropna(subset=['Plate #', 'Well #', '# kinks'], inplace=True)\n",
    "metadata.dropna(how='all', axis=1, inplace=True)\n",
    "# metadata.dropna(inplace=True)\n",
    "print(metadata.shape)\n",
    "metadata['plate_well'] = metadata['Plate #'] + '_' + metadata['Well #'].astype(int).astype(str)\n",
    "metadata.columns = [col.split('\\n')[0].replace(' ', '_').replace('?', '').lower() for col in metadata.columns]\n",
    "metadata.head()\n",
    "# metadata['unnamed:_11'].astype(str).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1091, 7)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob \n",
    "\n",
    "fil = pd.read_table('ftp_files.txt', header=None)[0].str.split('/', expand=True)\n",
    "fil[['line', 'date']] = fil[2].str.split(' \\(', expand=True)\n",
    "fil['date'] = fil['date'].str.replace(')', '').str.split(' ', expand=True)[0]\n",
    "fil['line'] = fil['line'].str.split(' ', expand=True)[0]\n",
    "fil['plate'] = fil[1].str.split('_', expand=True, n=1)[0]\n",
    "fil[['well', 'channel']] = fil[3].str.split('--', expand=True)[[0, 4]]\n",
    "fil[3] = fil[3].str.split('\\.', expand=True)[0]\n",
    "fil = fil.groupby(['line', 'date', 'well', 'plate', 'channel'])[3].first().unstack().reset_index()\n",
    "fil['plate_well'] = fil['plate'] + '_' + fil['well'].str.replace('WE0', '').astype(int).astype(str)\n",
    "fil.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na (157, 18)\n",
      "Merge shape (1091, 18)\n",
      "line_x  line_y\n",
      "23-2    22-1      2\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_x</th>\n",
       "      <th>date</th>\n",
       "      <th>well</th>\n",
       "      <th>plate</th>\n",
       "      <th>CO4</th>\n",
       "      <th>CO6</th>\n",
       "      <th>plate_well</th>\n",
       "      <th>start_exposure</th>\n",
       "      <th>line_y</th>\n",
       "      <th>exposure_type</th>\n",
       "      <th>stop_exposure</th>\n",
       "      <th>fixed</th>\n",
       "      <th>imaged</th>\n",
       "      <th>plate_#</th>\n",
       "      <th>well_#</th>\n",
       "      <th>kinked</th>\n",
       "      <th>#_kinks</th>\n",
       "      <th>severity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>22-1</td>\n",
       "      <td>25.07</td>\n",
       "      <td>WE00040</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>WE00040---D009--PO01--LO001--CO4--SL001--PX325...</td>\n",
       "      <td>WE00040---D009--PO01--LO001--CO6--SL001--PX325...</td>\n",
       "      <td>Plate 4_40</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>22-1</td>\n",
       "      <td>Ziram</td>\n",
       "      <td>2022-08-03</td>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>2022-08-17 00:00:00</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10+</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>23-2</td>\n",
       "      <td>25.07</td>\n",
       "      <td>WE00040</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>WE00040---D009--PO01--LO001--CO4--SL001--PX325...</td>\n",
       "      <td>WE00040---D009--PO01--LO001--CO6--SL001--PX325...</td>\n",
       "      <td>Plate 4_40</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>22-1</td>\n",
       "      <td>Ziram</td>\n",
       "      <td>2022-08-03</td>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>2022-08-17 00:00:00</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10+</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>22-1</td>\n",
       "      <td>25.07</td>\n",
       "      <td>WE00043</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>WE00043---D006--PO01--LO001--CO4--SL001--PX325...</td>\n",
       "      <td>WE00043---D006--PO01--LO001--CO6--SL001--PX325...</td>\n",
       "      <td>Plate 4_43</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>22-1</td>\n",
       "      <td>Ziram</td>\n",
       "      <td>2022-08-03</td>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>2022-08-17 00:00:00</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>23-2</td>\n",
       "      <td>25.07</td>\n",
       "      <td>WE00043</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>WE00043---D006--PO01--LO001--CO4--SL001--PX325...</td>\n",
       "      <td>WE00043---D006--PO01--LO001--CO6--SL001--PX325...</td>\n",
       "      <td>Plate 4_43</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>22-1</td>\n",
       "      <td>Ziram</td>\n",
       "      <td>2022-08-03</td>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>2022-08-17 00:00:00</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>22-1</td>\n",
       "      <td>25.07</td>\n",
       "      <td>WE00044</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>WE00044---D005--PO01--LO001--CO4--SL001--PX325...</td>\n",
       "      <td>WE00044---D005--PO01--LO001--CO6--SL001--PX325...</td>\n",
       "      <td>Plate 4_44</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>23-2</td>\n",
       "      <td>25.07</td>\n",
       "      <td>WE00044</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>WE00044---D005--PO01--LO001--CO4--SL001--PX325...</td>\n",
       "      <td>WE00044---D005--PO01--LO001--CO6--SL001--PX325...</td>\n",
       "      <td>Plate 4_44</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>22-1</td>\n",
       "      <td>25.07</td>\n",
       "      <td>WE00047</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>WE00047---D002--PO01--LO001--CO4--SL001--PX325...</td>\n",
       "      <td>WE00047---D002--PO01--LO001--CO6--SL001--PX325...</td>\n",
       "      <td>Plate 4_47</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>23-2</td>\n",
       "      <td>25.07</td>\n",
       "      <td>WE00047</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>WE00047---D002--PO01--LO001--CO4--SL001--PX325...</td>\n",
       "      <td>WE00047---D002--PO01--LO001--CO6--SL001--PX325...</td>\n",
       "      <td>Plate 4_47</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>22-1</td>\n",
       "      <td>25.07</td>\n",
       "      <td>WE00048</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>WE00048---D001--PO01--LO001--CO4--SL001--PX325...</td>\n",
       "      <td>WE00048---D001--PO01--LO001--CO6--SL001--PX325...</td>\n",
       "      <td>Plate 4_48</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>23-2</td>\n",
       "      <td>25.07</td>\n",
       "      <td>WE00048</td>\n",
       "      <td>Plate 4</td>\n",
       "      <td>WE00048---D001--PO01--LO001--CO4--SL001--PX325...</td>\n",
       "      <td>WE00048---D001--PO01--LO001--CO6--SL001--PX325...</td>\n",
       "      <td>Plate 4_48</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    line_x   date     well    plate  \\\n",
       "423   22-1  25.07  WE00040  Plate 4   \n",
       "424   23-2  25.07  WE00040  Plate 4   \n",
       "427   22-1  25.07  WE00043  Plate 4   \n",
       "428   23-2  25.07  WE00043  Plate 4   \n",
       "429   22-1  25.07  WE00044  Plate 4   \n",
       "430   23-2  25.07  WE00044  Plate 4   \n",
       "431   22-1  25.07  WE00047  Plate 4   \n",
       "432   23-2  25.07  WE00047  Plate 4   \n",
       "433   22-1  25.07  WE00048  Plate 4   \n",
       "434   23-2  25.07  WE00048  Plate 4   \n",
       "\n",
       "                                                   CO4  \\\n",
       "423  WE00040---D009--PO01--LO001--CO4--SL001--PX325...   \n",
       "424  WE00040---D009--PO01--LO001--CO4--SL001--PX325...   \n",
       "427  WE00043---D006--PO01--LO001--CO4--SL001--PX325...   \n",
       "428  WE00043---D006--PO01--LO001--CO4--SL001--PX325...   \n",
       "429  WE00044---D005--PO01--LO001--CO4--SL001--PX325...   \n",
       "430  WE00044---D005--PO01--LO001--CO4--SL001--PX325...   \n",
       "431  WE00047---D002--PO01--LO001--CO4--SL001--PX325...   \n",
       "432  WE00047---D002--PO01--LO001--CO4--SL001--PX325...   \n",
       "433  WE00048---D001--PO01--LO001--CO4--SL001--PX325...   \n",
       "434  WE00048---D001--PO01--LO001--CO4--SL001--PX325...   \n",
       "\n",
       "                                                   CO6  plate_well  \\\n",
       "423  WE00040---D009--PO01--LO001--CO6--SL001--PX325...  Plate 4_40   \n",
       "424  WE00040---D009--PO01--LO001--CO6--SL001--PX325...  Plate 4_40   \n",
       "427  WE00043---D006--PO01--LO001--CO6--SL001--PX325...  Plate 4_43   \n",
       "428  WE00043---D006--PO01--LO001--CO6--SL001--PX325...  Plate 4_43   \n",
       "429  WE00044---D005--PO01--LO001--CO6--SL001--PX325...  Plate 4_44   \n",
       "430  WE00044---D005--PO01--LO001--CO6--SL001--PX325...  Plate 4_44   \n",
       "431  WE00047---D002--PO01--LO001--CO6--SL001--PX325...  Plate 4_47   \n",
       "432  WE00047---D002--PO01--LO001--CO6--SL001--PX325...  Plate 4_47   \n",
       "433  WE00048---D001--PO01--LO001--CO6--SL001--PX325...  Plate 4_48   \n",
       "434  WE00048---D001--PO01--LO001--CO6--SL001--PX325...  Plate 4_48   \n",
       "\n",
       "    start_exposure line_y exposure_type stop_exposure      fixed  \\\n",
       "423     2022-07-25   22-1         Ziram    2022-08-03 2022-08-08   \n",
       "424     2022-07-25   22-1         Ziram    2022-08-03 2022-08-08   \n",
       "427     2022-07-25   22-1         Ziram    2022-08-03 2022-08-08   \n",
       "428     2022-07-25   22-1         Ziram    2022-08-03 2022-08-08   \n",
       "429            NaT    NaN           NaN           NaT        NaT   \n",
       "430            NaT    NaN           NaN           NaT        NaT   \n",
       "431            NaT    NaN           NaN           NaT        NaT   \n",
       "432            NaT    NaN           NaN           NaT        NaT   \n",
       "433            NaT    NaN           NaN           NaT        NaT   \n",
       "434            NaT    NaN           NaN           NaT        NaT   \n",
       "\n",
       "                  imaged  plate_#  well_# kinked #_kinks  severity_score  \n",
       "423  2022-08-17 00:00:00  Plate 4    40.0      1     10+             4.0  \n",
       "424  2022-08-17 00:00:00  Plate 4    40.0      1     10+             4.0  \n",
       "427  2022-08-17 00:00:00  Plate 4    43.0      1      10             4.0  \n",
       "428  2022-08-17 00:00:00  Plate 4    43.0      1      10             4.0  \n",
       "429                  NaN      NaN     NaN    NaN     NaN             NaN  \n",
       "430                  NaN      NaN     NaN    NaN     NaN             NaN  \n",
       "431                  NaN      NaN     NaN    NaN     NaN             NaN  \n",
       "432                  NaN      NaN     NaN    NaN     NaN             NaN  \n",
       "433                  NaN      NaN     NaN    NaN     NaN             NaN  \n",
       "434                  NaN      NaN     NaN    NaN     NaN             NaN  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge = pd.merge(fil, metadata, on='plate_well', how='outer')\n",
    "\n",
    "print('na', merge[merge['kinked'].isna()].shape)\n",
    "print('Merge shape', merge.shape)\n",
    "for col in merge.filter(regex='.*_x').columns:\n",
    "    print(merge[merge[col] != merge[col.replace('x', 'y')]].filter(regex=col[:-2]).value_counts())\n",
    "\n",
    "merge[merge.duplicated(keep=False, subset='plate_well')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 18)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#verif \n",
    "\n",
    "\n",
    "# To identify if any is missing\n",
    "fil[fil['plate_well'].isin(merge['plate_well']) == False]\n",
    "metadata[metadata['plate_well'].isin(merge['plate_well'])== False]\n",
    "\n",
    "## NB: Still missing one plate --> reload plate 11!\n",
    "\n",
    "# Check for duplicates \n",
    "merge[merge['plate_well'].duplicated(keep=False)].shape\n",
    "# merge[merge['plate_well'].duplicated(keep=False)].to_csv('Double_imaged_individuals_01062023.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge[merge['plate_well'].duplicated(keep='first') == False].to_csv('Germany_data_plate_image.csv', index=False)\n",
    "merge.to_csv('Germany_Data_Organized_metadata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148 1147\n",
      "(0, 18) (1, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "932"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import glob\n",
    "\n",
    "file_co6 = [os.path.basename(file).split('.')[0] for file in glob.glob('dataset_ziram_CO6/*/*')]\n",
    "file_co4 = [os.path.basename(file).split('.')[0] for file in glob.glob('dataset_ziram_CO4/*/*')]\n",
    "\n",
    "print(len(file_co6), len(file_co4))\n",
    "# print(merge['CO6'].unique())\n",
    "\n",
    "print(merge[merge['CO6'].isin(file_co6)==False].shape, merge[merge['CO4'].isin(file_co4)==False].shape)\n",
    "miss_co6 = merge[merge['CO6'].isin(file_co6)==False]['plate_well'].tolist()\n",
    "miss_co4 = merge[merge['CO4'].isin(file_co4)==False]['plate_well'].tolist()\n",
    "\n",
    "# print(len(miss_co6), len(miss_co4))\n",
    "# set(miss_co4) - set(miss_co6)\n",
    "\n",
    "# print(\n",
    "# merge[merge['plate_well'].duplicated(keep=False)].shape,\n",
    "# merge[merge['CO4'].duplicated(keep=False)].shape\n",
    "# )\n",
    "# set(co4_ls) - set(co6_ls)\n",
    "\n",
    "merge['plate_well'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.DataFrame(glob.glob('dataset_ziram_CO6/*/*'))[0].str.split('/', expand=True)\n",
    "df4 = pd.DataFrame(glob.glob('dataset_ziram_CO4/*/*'))[0].str.split('/', expand=True)\n",
    "df6[2] = df6[2].str.split('.',expand=True)[0]\n",
    "df4[2] = df4[2].str.split('.',expand=True)[0]\n",
    "\n",
    "rep = pd.read_csv('dataset_ziram_CO4/Repartition_images_sets.csv')\n",
    "#CO6 test set\n",
    "\n",
    "rep[rep['severity_score'].isna()].shape\n",
    "\n",
    "test6 = df6[df6[1] == 'test_set'][2].tolist()\n",
    "test4 = df4[df4[1] == 'test_set'][2].tolist()\n",
    "train6 = df6[df6[1] == 'training_set'][2].tolist()\n",
    "train4 = df4[df4[1] == 'training_set'][2].tolist()\n",
    "\n",
    "rep[rep['CO4'].isin(train4)].shape, len(train4), \n",
    "len(set(rep['CO6']) - set(train6))\n",
    "len(set(train6) & set(rep['CO6']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "bsub -oo CO4.out -M1G 'python3 data_split.py \"dataset_cnn_CO4/*\" Germany_Data_Organized_metadata.csv severity_score -p dataset_ziram_CO4 -n CO4' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.677237\n",
       "0    0.322763\n",
       "Name: kinked, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.rename(columns={merge.columns[12]: 'kinked'}, inplace=True)\n",
    "merge['kinked'] = merge['kinked'].replace('1?', None, regex=False)\n",
    "merge['kinked'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 114\n",
      "0 56\n"
     ]
    }
   ],
   "source": [
    "# check for the datasplit\n",
    "dataset_path = 'BLOU'\n",
    "column_sep = 'kinked'\n",
    "ratio_test = 0.2\n",
    "\n",
    "dict_folder = {'test':os.path.join(dataset_path, 'test_set'),\n",
    "                'training': os.path.join(dataset_path, 'training_set')}\n",
    "\n",
    "df = merge[merge['plate_well'].duplicated() == False].dropna()\n",
    "\n",
    "# df['image'] = df['image'].str.rsplit('/', n=1, expand=True)[1]\n",
    "\n",
    "assert df[0].value_counts().max() == 1, 'Problem with naming images, repetition or missed value !'\n",
    "# df.rename(columns={'Plate (Imaged)':'plate', 'Well #': 'well', '# kinks': 'kinks', 'Severity Score:': 'score'}, inplace=True)\n",
    "# df.loc[df['Exposure'] == 'DMSO', 'treated'] = 'Not_treated'\n",
    "# df.loc[df['Exposure'] != 'DMSO', 'treated'] = 'Treated'\n",
    "image_random_ls = []\n",
    "for val, n_val in dict(df[column_sep].value_counts()).items():\n",
    "    print(val, int(n_val * ratio_test))\n",
    "    image_random_ls  += df[df[ column_sep].astype(str) == str(val)].sample(int(n_val * ratio_test))[0].tolist()\n",
    "    dict_folder[f'training_{str(val)}'] = os.path.join(dataset_path, 'training_set', str(val))\n",
    "    dict_folder[f'test_{str(val)}'] = os.path.join(dataset_path, 'test_set', str(val))\n",
    "\n",
    "\n",
    "\n",
    "for n, file in enumerate(df[0].unique()):\n",
    "    image = file.split('/')[-1]\n",
    "    try:\n",
    "        val = df.loc[(df[0] == file), column_sep].tolist()[0]\n",
    "    except:\n",
    "        print(f'ERROR(file {n}): \\n',  df.loc[(df[0] == image)])\n",
    "    # print(image, df.loc[(df['image']== image), 'image'].nunique(), val)\n",
    "    if file in image_random_ls:\n",
    "        destination_folder = f'test_{str(val)}'\n",
    "    else:\n",
    "        destination_folder = f'training_{str(val)}'\n",
    "    \n",
    "    # move_file(image, destination_folder)\n",
    "    df.loc[(df[0].str.contains(image)), 'folder'] = dict_folder[destination_folder]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training_set    0.800469\n",
       "test_set        0.199531\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blou = df['folder'].str.split('/', expand=True)\n",
    "\n",
    "# Check the repartition of the files\n",
    "blou[blou[1].str.contains('training')].value_counts(normalize=True)\n",
    "blou[blou[1].str.contains('test')].value_counts(normalize=True)\n",
    "blou[2].value_counts(normalize=True)\n",
    "blou[1].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image'] = df[0].str.split('/', expand=True)[3]\n",
    "df.drop_duplicates(subset='plate_well', inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.drop('folder', axis=1).to_csv('Germany_data_plate_image.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for repartition accross the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.348073\n",
       "4.0    0.234694\n",
       "3.0    0.160998\n",
       "2.0    0.155329\n",
       "1.0    0.100907\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_cnn/Repartition_images_sets.csv')\n",
    "print('Total repartition', df['score'].value_counts(normalize=True))\n",
    "print('\\nTrain\\n', df[df['folder'] == 'training_set']['score'].value_counts(normalize=True))\n",
    "print('\\nTest\\n', df[df['folder'] == 'test_set']['score'].value_counts(normalize=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table with all files according to channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('/homes/fanny/medaka/ziram_analysis/all_files_08062023.txt', header=None)[0].str.split('/', expand=True)\n",
    "df['channel'] = df[3].str.split('--', expand=True)[4]\n",
    "df['plate'] = df[1].str.split('_', n=1, expand=True)[0]\n",
    "df['well'] = df[3].str.split('---', n=1, expand=True)[0].str.replace('WE000', '')\n",
    "df.groupby(['plate', 'well', 'channel']).first()[3].unstack().reset_index().to_csv('channel_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/homes/fanny/medaka/ziram_analysis/channel_table.csv')\n",
    "sets = pd.read_csv('/homes/fanny/medaka/ziram_analysis/dataset_cnn_CO4/Repartition_images_sets.csv')\n",
    "df['plate_well'] = df['plate'] + '_' + df['well'].astype(str)\n",
    "merge = pd.merge(sets.drop(['filename', 'Well', 'Plate', ], axis=1), df, on=[\"plate_well\", 'plate', 'well'])\n",
    "merge.to_csv('Plate_well_repartition_all_chanels.csv', index=False)\n",
    "# df.rename(columns={})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WE00082---G010--PO01--LO001--CO6--SL001--PX32500--PW0100--IN0020--TM283--X095544--Y064992--Z210481--T2692481699',\n",
       " 'WE00002---A002--PO01--LO001--CO6--SL001--PX32500--PW0100--IN0020--TM283--X023472--Y011163--Z213937--T2349215044',\n",
       " 'WE00022---B003--PO01--LO001--CO6--SL001--PX32500--PW0100--IN0020--TM278--X032481--Y020134--Z214475--T2851745436',\n",
       " 'WE00028---C004--PO01--LO001--CO6--SL001--PX32500--PW0100--IN0020--TM280--X041490--Y029106--Z214911--T2271373564',\n",
       " 'WE00018---B007--PO01--LO001--CO6--SL001--PX32500--PW0100--IN0020--TM280--X068517--Y020134--Z210593--T2253443781']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "df = pd.read_csv('/homes/fanny/medaka/ziram_analysis/Plate_well_repartition_all_chanels.csv')\n",
    "\n",
    "df = df[df['folder'] == 'training_set']\n",
    "\n",
    "co6 = [im.split('.')[0].split('/')[2] for im in glob.glob('dataset_ziram_CO6/training_set/*png')]\n",
    "co4 = [im.split('.')[0].split('/')[2] for im in glob.glob('dataset_ziram_CO4/training_set/*png')]\n",
    "\n",
    "list_image = []\n",
    "for image in co6:\n",
    "    if image not in df['CO6'].str.split('.', expand=True)[0].tolist():\n",
    "        list_image.append(image)\n",
    "ser = pd.Series(list_image).to_csv('spare image' , header=False, index=False)\n",
    "\n",
    "\n",
    "# df = df[(df['CO6'].str.split('.', expand=True)[0].isin(co6)) & (df['CO4'].str.split('.', expand=True)[0].isin(co4))]\n",
    "# print(df[].shape)\n",
    "# co6[:10]\n",
    "co6[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CO6'] = df['CO6'].astype(str)\n",
    "df['CO4'] = df['CO4'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO4</th>\n",
       "      <th>CO6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Plate 3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 15</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 11</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 5</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 1</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 4</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 17</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 10</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 9</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 6</th>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 8</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 14</th>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 16</th>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 12</th>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 7</th>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate 13</th>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CO4  CO6\n",
       "plate             \n",
       "Plate 3     8    8\n",
       "Plate 15   10   10\n",
       "Plate 11   12   12\n",
       "Plate 5    14   14\n",
       "Plate 1    17   17\n",
       "Plate 4    22   22\n",
       "Plate 17   33   33\n",
       "Plate 10   69   69\n",
       "Plate 9    70   70\n",
       "Plate 6    72   72\n",
       "Plate 8    74   74\n",
       "Plate 14   78   78\n",
       "Plate 16   81   81\n",
       "Plate 12   82   82\n",
       "Plate 7    82   82\n",
       "Plate 13   83   83"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('plate')[['CO4', 'CO6']].nunique(dropna=False).sort_values('CO6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ziram_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
